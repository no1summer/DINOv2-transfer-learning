{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/xiatian2/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset, RandomSampler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import skimage.io as io\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.init import trunc_normal_\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "\n",
    "class DINOHead(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim,\n",
    "        out_dim,\n",
    "        use_bn=False,\n",
    "        nlayers=3,\n",
    "        hidden_dim=2048,\n",
    "        bottleneck_dim=256,\n",
    "        mlp_bias=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        nlayers = max(nlayers, 1)\n",
    "        self.mlp = _build_mlp(nlayers, in_dim, bottleneck_dim, hidden_dim=hidden_dim, use_bn=use_bn, bias=mlp_bias)\n",
    "        self.apply(self._init_weights)\n",
    "        self.last_layer = weight_norm(nn.Linear(bottleneck_dim, out_dim, bias=False))\n",
    "        self.last_layer.weight_g.data.fill_(1)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=0.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        eps = 1e-6 if x.dtype == torch.float16 else 1e-12\n",
    "        x = nn.functional.normalize(x, dim=-1, p=2, eps=eps)\n",
    "        x = self.last_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def _build_mlp(nlayers, in_dim, bottleneck_dim, hidden_dim=None, use_bn=False, bias=True):\n",
    "    if nlayers == 1:\n",
    "        return nn.Linear(in_dim, bottleneck_dim, bias=bias)\n",
    "    else:\n",
    "        layers = [nn.Linear(in_dim, hidden_dim, bias=bias)]\n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "        layers.append(nn.GELU())\n",
    "        for _ in range(nlayers - 2):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim, bias=bias))\n",
    "            if use_bn:\n",
    "                layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            layers.append(nn.GELU())\n",
    "        layers.append(nn.Linear(hidden_dim, bottleneck_dim, bias=bias))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "\n",
    "dinov2_vits14_lc = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14_lc')\n",
    "dinov2_vits14_lc_batch9=dinov2_vits14_lc\n",
    "dinov2_vits14_lc_batch9.linear_head=DINOHead(in_dim=1920,out_dim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_LinearClassifierWrapper(\n",
       "  (backbone): DinoVisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 384, kernel_size=(14, 14), stride=(14, 14))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x NestedTensorBlock(\n",
       "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MemEffAttention(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (linear_head): DINOHead(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=1920, out_features=2048, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    )\n",
       "    (last_layer): Linear(in_features=256, out_features=4, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dinov2_vits14_lc_batch9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for _LinearClassifierWrapper:\n\tMissing key(s) in state_dict: \"backbone.cls_token\", \"backbone.pos_embed\", \"backbone.mask_token\", \"backbone.patch_embed.proj.weight\", \"backbone.patch_embed.proj.bias\", \"backbone.blocks.0.norm1.weight\", \"backbone.blocks.0.norm1.bias\", \"backbone.blocks.0.attn.qkv.weight\", \"backbone.blocks.0.attn.qkv.bias\", \"backbone.blocks.0.attn.proj.weight\", \"backbone.blocks.0.attn.proj.bias\", \"backbone.blocks.0.ls1.gamma\", \"backbone.blocks.0.norm2.weight\", \"backbone.blocks.0.norm2.bias\", \"backbone.blocks.0.mlp.fc1.weight\", \"backbone.blocks.0.mlp.fc1.bias\", \"backbone.blocks.0.mlp.fc2.weight\", \"backbone.blocks.0.mlp.fc2.bias\", \"backbone.blocks.0.ls2.gamma\", \"backbone.blocks.1.norm1.weight\", \"backbone.blocks.1.norm1.bias\", \"backbone.blocks.1.attn.qkv.weight\", \"backbone.blocks.1.attn.qkv.bias\", \"backbone.blocks.1.attn.proj.weight\", \"backbone.blocks.1.attn.proj.bias\", \"backbone.blocks.1.ls1.gamma\", \"backbone.blocks.1.norm2.weight\", \"backbone.blocks.1.norm2.bias\", \"backbone.blocks.1.mlp.fc1.weight\", \"backbone.blocks.1.mlp.fc1.bias\", \"backbone.blocks.1.mlp.fc2.weight\", \"backbone.blocks.1.mlp.fc2.bias\", \"backbone.blocks.1.ls2.gamma\", \"backbone.blocks.2.norm1.weight\", \"backbone.blocks.2.norm1.bias\", \"backbone.blocks.2.attn.qkv.weight\", \"backbone.blocks.2.attn.qkv.bias\", \"backbone.blocks.2.attn.proj.weight\", \"backbone.blocks.2.attn.proj.bias\", \"backbone.blocks.2.ls1.gamma\", \"backbone.blocks.2.norm2.weight\", \"backbone.blocks.2.norm2.bias\", \"backbone.blocks.2.mlp.fc1.weight\", \"backbone.blocks.2.mlp.fc1.bias\", \"backbone.blocks.2.mlp.fc2.weight\", \"backbone.blocks.2.mlp.fc2.bias\", \"backbone.blocks.2.ls2.gamma\", \"backbone.blocks.3.norm1.weight\", \"backbone.blocks.3.norm1.bias\", \"backbone.blocks.3.attn.qkv.weight\", \"backbone.blocks.3.attn.qkv.bias\", \"backbone.blocks.3.attn.proj.weight\", \"backbone.blocks.3.attn.proj.bias\", \"backbone.blocks.3.ls1.gamma\", \"backbone.blocks.3.norm2.weight\", \"backbone.blocks.3.norm2.bias\", \"backbone.blocks.3.mlp.fc1.weight\", \"backbone.blocks.3.mlp.fc1.bias\", \"backbone.blocks.3.mlp.fc2.weight\", \"backbone.blocks.3.mlp.fc2.bias\", \"backbone.blocks.3.ls2.gamma\", \"backbone.blocks.4.norm1.weight\", \"backbone.blocks.4.norm1.bias\", \"backbone.blocks.4.attn.qkv.weight\", \"backbone.blocks.4.attn.qkv.bias\", \"backbone.blocks.4.attn.proj.weight\", \"backbone.blocks.4.attn.proj.bias\", \"backbone.blocks.4.ls1.gamma\", \"backbone.blocks.4.norm2.weight\", \"backbone.blocks.4.norm2.bias\", \"backbone.blocks.4.mlp.fc1.weight\", \"backbone.blocks.4.mlp.fc1.bias\", \"backbone.blocks.4.mlp.fc2.weight\", \"backbone.blocks.4.mlp.fc2.bias\", \"backbone.blocks.4.ls2.gamma\", \"backbone.blocks.5.norm1.weight\", \"backbone.blocks.5.norm1.bias\", \"backbone.blocks.5.attn.qkv.weight\", \"backbone.blocks.5.attn.qkv.bias\", \"backbone.blocks.5.attn.proj.weight\", \"backbone.blocks.5.attn.proj.bias\", \"backbone.blocks.5.ls1.gamma\", \"backbone.blocks.5.norm2.weight\", \"backbone.blocks.5.norm2.bias\", \"backbone.blocks.5.mlp.fc1.weight\", \"backbone.blocks.5.mlp.fc1.bias\", \"backbone.blocks.5.mlp.fc2.weight\", \"backbone.blocks.5.mlp.fc2.bias\", \"backbone.blocks.5.ls2.gamma\", \"backbone.blocks.6.norm1.weight\", \"backbone.blocks.6.norm1.bias\", \"backbone.blocks.6.attn.qkv.weight\", \"backbone.blocks.6.attn.qkv.bias\", \"backbone.blocks.6.attn.proj.weight\", \"backbone.blocks.6.attn.proj.bias\", \"backbone.blocks.6.ls1.gamma\", \"backbone.blocks.6.norm2.weight\", \"backbone.blocks.6.norm2.bias\", \"backbone.blocks.6.mlp.fc1.weight\", \"backbone.blocks.6.mlp.fc1.bias\", \"backbone.blocks.6.mlp.fc2.weight\", \"backbone.blocks.6.mlp.fc2.bias\", \"backbone.blocks.6.ls2.gamma\", \"backbone.blocks.7.norm1.weight\", \"backbone.blocks.7.norm1.bias\", \"backbone.blocks.7.attn.qkv.weight\", \"backbone.blocks.7.attn.qkv.bias\", \"backbone.blocks.7.attn.proj.weight\", \"backbone.blocks.7.attn.proj.bias\", \"backbone.blocks.7.ls1.gamma\", \"backbone.blocks.7.norm2.weight\", \"backbone.blocks.7.norm2.bias\", \"backbone.blocks.7.mlp.fc1.weight\", \"backbone.blocks.7.mlp.fc1.bias\", \"backbone.blocks.7.mlp.fc2.weight\", \"backbone.blocks.7.mlp.fc2.bias\", \"backbone.blocks.7.ls2.gamma\", \"backbone.blocks.8.norm1.weight\", \"backbone.blocks.8.norm1.bias\", \"backbone.blocks.8.attn.qkv.weight\", \"backbone.blocks.8.attn.qkv.bias\", \"backbone.blocks.8.attn.proj.weight\", \"backbone.blocks.8.attn.proj.bias\", \"backbone.blocks.8.ls1.gamma\", \"backbone.blocks.8.norm2.weight\", \"backbone.blocks.8.norm2.bias\", \"backbone.blocks.8.mlp.fc1.weight\", \"backbone.blocks.8.mlp.fc1.bias\", \"backbone.blocks.8.mlp.fc2.weight\", \"backbone.blocks.8.mlp.fc2.bias\", \"backbone.blocks.8.ls2.gamma\", \"backbone.blocks.9.norm1.weight\", \"backbone.blocks.9.norm1.bias\", \"backbone.blocks.9.attn.qkv.weight\", \"backbone.blocks.9.attn.qkv.bias\", \"backbone.blocks.9.attn.proj.weight\", \"backbone.blocks.9.attn.proj.bias\", \"backbone.blocks.9.ls1.gamma\", \"backbone.blocks.9.norm2.weight\", \"backbone.blocks.9.norm2.bias\", \"backbone.blocks.9.mlp.fc1.weight\", \"backbone.blocks.9.mlp.fc1.bias\", \"backbone.blocks.9.mlp.fc2.weight\", \"backbone.blocks.9.mlp.fc2.bias\", \"backbone.blocks.9.ls2.gamma\", \"backbone.blocks.10.norm1.weight\", \"backbone.blocks.10.norm1.bias\", \"backbone.blocks.10.attn.qkv.weight\", \"backbone.blocks.10.attn.qkv.bias\", \"backbone.blocks.10.attn.proj.weight\", \"backbone.blocks.10.attn.proj.bias\", \"backbone.blocks.10.ls1.gamma\", \"backbone.blocks.10.norm2.weight\", \"backbone.blocks.10.norm2.bias\", \"backbone.blocks.10.mlp.fc1.weight\", \"backbone.blocks.10.mlp.fc1.bias\", \"backbone.blocks.10.mlp.fc2.weight\", \"backbone.blocks.10.mlp.fc2.bias\", \"backbone.blocks.10.ls2.gamma\", \"backbone.blocks.11.norm1.weight\", \"backbone.blocks.11.norm1.bias\", \"backbone.blocks.11.attn.qkv.weight\", \"backbone.blocks.11.attn.qkv.bias\", \"backbone.blocks.11.attn.proj.weight\", \"backbone.blocks.11.attn.proj.bias\", \"backbone.blocks.11.ls1.gamma\", \"backbone.blocks.11.norm2.weight\", \"backbone.blocks.11.norm2.bias\", \"backbone.blocks.11.mlp.fc1.weight\", \"backbone.blocks.11.mlp.fc1.bias\", \"backbone.blocks.11.mlp.fc2.weight\", \"backbone.blocks.11.mlp.fc2.bias\", \"backbone.blocks.11.ls2.gamma\", \"backbone.norm.weight\", \"backbone.norm.bias\", \"linear_head.mlp.0.weight\", \"linear_head.mlp.0.bias\", \"linear_head.mlp.2.weight\", \"linear_head.mlp.2.bias\", \"linear_head.mlp.4.weight\", \"linear_head.mlp.4.bias\", \"linear_head.last_layer.weight_g\", \"linear_head.last_layer.weight_v\". \n\tUnexpected key(s) in state_dict: \"weight\", \"bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m dinov2_vits14_lc_batch9\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/xiatian2/VIT/dinov2_vits14_reg4_linear4_head.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\n",
      "File \u001b[0;32m~/anaconda3/envs/swin_unetr/lib/python3.12/site-packages/torch/nn/modules/module.py:2189\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2184\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2185\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2186\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2190\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for _LinearClassifierWrapper:\n\tMissing key(s) in state_dict: \"backbone.cls_token\", \"backbone.pos_embed\", \"backbone.mask_token\", \"backbone.patch_embed.proj.weight\", \"backbone.patch_embed.proj.bias\", \"backbone.blocks.0.norm1.weight\", \"backbone.blocks.0.norm1.bias\", \"backbone.blocks.0.attn.qkv.weight\", \"backbone.blocks.0.attn.qkv.bias\", \"backbone.blocks.0.attn.proj.weight\", \"backbone.blocks.0.attn.proj.bias\", \"backbone.blocks.0.ls1.gamma\", \"backbone.blocks.0.norm2.weight\", \"backbone.blocks.0.norm2.bias\", \"backbone.blocks.0.mlp.fc1.weight\", \"backbone.blocks.0.mlp.fc1.bias\", \"backbone.blocks.0.mlp.fc2.weight\", \"backbone.blocks.0.mlp.fc2.bias\", \"backbone.blocks.0.ls2.gamma\", \"backbone.blocks.1.norm1.weight\", \"backbone.blocks.1.norm1.bias\", \"backbone.blocks.1.attn.qkv.weight\", \"backbone.blocks.1.attn.qkv.bias\", \"backbone.blocks.1.attn.proj.weight\", \"backbone.blocks.1.attn.proj.bias\", \"backbone.blocks.1.ls1.gamma\", \"backbone.blocks.1.norm2.weight\", \"backbone.blocks.1.norm2.bias\", \"backbone.blocks.1.mlp.fc1.weight\", \"backbone.blocks.1.mlp.fc1.bias\", \"backbone.blocks.1.mlp.fc2.weight\", \"backbone.blocks.1.mlp.fc2.bias\", \"backbone.blocks.1.ls2.gamma\", \"backbone.blocks.2.norm1.weight\", \"backbone.blocks.2.norm1.bias\", \"backbone.blocks.2.attn.qkv.weight\", \"backbone.blocks.2.attn.qkv.bias\", \"backbone.blocks.2.attn.proj.weight\", \"backbone.blocks.2.attn.proj.bias\", \"backbone.blocks.2.ls1.gamma\", \"backbone.blocks.2.norm2.weight\", \"backbone.blocks.2.norm2.bias\", \"backbone.blocks.2.mlp.fc1.weight\", \"backbone.blocks.2.mlp.fc1.bias\", \"backbone.blocks.2.mlp.fc2.weight\", \"backbone.blocks.2.mlp.fc2.bias\", \"backbone.blocks.2.ls2.gamma\", \"backbone.blocks.3.norm1.weight\", \"backbone.blocks.3.norm1.bias\", \"backbone.blocks.3.attn.qkv.weight\", \"backbone.blocks.3.attn.qkv.bias\", \"backbone.blocks.3.attn.proj.weight\", \"backbone.blocks.3.attn.proj.bias\", \"backbone.blocks.3.ls1.gamma\", \"backbone.blocks.3.norm2.weight\", \"backbone.blocks.3.norm2.bias\", \"backbone.blocks.3.mlp.fc1.weight\", \"backbone.blocks.3.mlp.fc1.bias\", \"backbone.blocks.3.mlp.fc2.weight\", \"backbone.blocks.3.mlp.fc2.bias\", \"backbone.blocks.3.ls2.gamma\", \"backbone.blocks.4.norm1.weight\", \"backbone.blocks.4.norm1.bias\", \"backbone.blocks.4.attn.qkv.weight\", \"backbone.blocks.4.attn.qkv.bias\", \"backbone.blocks.4.attn.proj.weight\", \"backbone.blocks.4.attn.proj.bias\", \"backbone.blocks.4.ls1.gamma\", \"backbone.blocks.4.norm2.weight\", \"backbone.blocks.4.norm2.bias\", \"backbone.blocks.4.mlp.fc1.weight\", \"backbone.blocks.4.mlp.fc1.bias\", \"backbone.blocks.4.mlp.fc2.weight\", \"backbone.blocks.4.mlp.fc2.bias\", \"backbone.blocks.4.ls2.gamma\", \"backbone.blocks.5.norm1.weight\", \"backbone.blocks.5.norm1.bias\", \"backbone.blocks.5.attn.qkv.weight\", \"backbone.blocks.5.attn.qkv.bias\", \"backbone.blocks.5.attn.proj.weight\", \"backbone.blocks.5.attn.proj.bias\", \"backbone.blocks.5.ls1.gamma\", \"backbone.blocks.5.norm2.weight\", \"backbone.blocks.5.norm2.bias\", \"backbone.blocks.5.mlp.fc1.weight\", \"backbone.blocks.5.mlp.fc1.bias\", \"backbone.blocks.5.mlp.fc2.weight\", \"backbone.blocks.5.mlp.fc2.bias\", \"backbone.blocks.5.ls2.gamma\", \"backbone.blocks.6.norm1.weight\", \"backbone.blocks.6.norm1.bias\", \"backbone.blocks.6.attn.qkv.weight\", \"backbone.blocks.6.attn.qkv.bias\", \"backbone.blocks.6.attn.proj.weight\", \"backbone.blocks.6.attn.proj.bias\", \"backbone.blocks.6.ls1.gamma\", \"backbone.blocks.6.norm2.weight\", \"backbone.blocks.6.norm2.bias\", \"backbone.blocks.6.mlp.fc1.weight\", \"backbone.blocks.6.mlp.fc1.bias\", \"backbone.blocks.6.mlp.fc2.weight\", \"backbone.blocks.6.mlp.fc2.bias\", \"backbone.blocks.6.ls2.gamma\", \"backbone.blocks.7.norm1.weight\", \"backbone.blocks.7.norm1.bias\", \"backbone.blocks.7.attn.qkv.weight\", \"backbone.blocks.7.attn.qkv.bias\", \"backbone.blocks.7.attn.proj.weight\", \"backbone.blocks.7.attn.proj.bias\", \"backbone.blocks.7.ls1.gamma\", \"backbone.blocks.7.norm2.weight\", \"backbone.blocks.7.norm2.bias\", \"backbone.blocks.7.mlp.fc1.weight\", \"backbone.blocks.7.mlp.fc1.bias\", \"backbone.blocks.7.mlp.fc2.weight\", \"backbone.blocks.7.mlp.fc2.bias\", \"backbone.blocks.7.ls2.gamma\", \"backbone.blocks.8.norm1.weight\", \"backbone.blocks.8.norm1.bias\", \"backbone.blocks.8.attn.qkv.weight\", \"backbone.blocks.8.attn.qkv.bias\", \"backbone.blocks.8.attn.proj.weight\", \"backbone.blocks.8.attn.proj.bias\", \"backbone.blocks.8.ls1.gamma\", \"backbone.blocks.8.norm2.weight\", \"backbone.blocks.8.norm2.bias\", \"backbone.blocks.8.mlp.fc1.weight\", \"backbone.blocks.8.mlp.fc1.bias\", \"backbone.blocks.8.mlp.fc2.weight\", \"backbone.blocks.8.mlp.fc2.bias\", \"backbone.blocks.8.ls2.gamma\", \"backbone.blocks.9.norm1.weight\", \"backbone.blocks.9.norm1.bias\", \"backbone.blocks.9.attn.qkv.weight\", \"backbone.blocks.9.attn.qkv.bias\", \"backbone.blocks.9.attn.proj.weight\", \"backbone.blocks.9.attn.proj.bias\", \"backbone.blocks.9.ls1.gamma\", \"backbone.blocks.9.norm2.weight\", \"backbone.blocks.9.norm2.bias\", \"backbone.blocks.9.mlp.fc1.weight\", \"backbone.blocks.9.mlp.fc1.bias\", \"backbone.blocks.9.mlp.fc2.weight\", \"backbone.blocks.9.mlp.fc2.bias\", \"backbone.blocks.9.ls2.gamma\", \"backbone.blocks.10.norm1.weight\", \"backbone.blocks.10.norm1.bias\", \"backbone.blocks.10.attn.qkv.weight\", \"backbone.blocks.10.attn.qkv.bias\", \"backbone.blocks.10.attn.proj.weight\", \"backbone.blocks.10.attn.proj.bias\", \"backbone.blocks.10.ls1.gamma\", \"backbone.blocks.10.norm2.weight\", \"backbone.blocks.10.norm2.bias\", \"backbone.blocks.10.mlp.fc1.weight\", \"backbone.blocks.10.mlp.fc1.bias\", \"backbone.blocks.10.mlp.fc2.weight\", \"backbone.blocks.10.mlp.fc2.bias\", \"backbone.blocks.10.ls2.gamma\", \"backbone.blocks.11.norm1.weight\", \"backbone.blocks.11.norm1.bias\", \"backbone.blocks.11.attn.qkv.weight\", \"backbone.blocks.11.attn.qkv.bias\", \"backbone.blocks.11.attn.proj.weight\", \"backbone.blocks.11.attn.proj.bias\", \"backbone.blocks.11.ls1.gamma\", \"backbone.blocks.11.norm2.weight\", \"backbone.blocks.11.norm2.bias\", \"backbone.blocks.11.mlp.fc1.weight\", \"backbone.blocks.11.mlp.fc1.bias\", \"backbone.blocks.11.mlp.fc2.weight\", \"backbone.blocks.11.mlp.fc2.bias\", \"backbone.blocks.11.ls2.gamma\", \"backbone.norm.weight\", \"backbone.norm.bias\", \"linear_head.mlp.0.weight\", \"linear_head.mlp.0.bias\", \"linear_head.mlp.2.weight\", \"linear_head.mlp.2.bias\", \"linear_head.mlp.4.weight\", \"linear_head.mlp.4.bias\", \"linear_head.last_layer.weight_g\", \"linear_head.last_layer.weight_v\". \n\tUnexpected key(s) in state_dict: \"weight\", \"bias\". "
     ]
    }
   ],
   "source": [
    "model = dinov2_vits14_lc_batch9\n",
    "model.load_state_dict(torch.load('/Users/xiatian2/VIT/dinov2_vits14_reg4_linear4_head.pth'))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.4117647..7.4117646].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path='/Users/xiatian2/VIT/batch9/train/raw/WellA2_PointA2_0241_ChannelPhalloAF750,ZO1-AF488,DAPI_Seq1266.ome.tiff'\n",
    "x_before = io.imread(file_path)\n",
    "x_before=Image.fromarray((x_before / 256).astype('uint8')).convert('RGB')\n",
    "\n",
    "mean = (0.03, 0.08, 0.02) \n",
    "std = (0.02, 0.04, 0.04)\n",
    "#mean = (-0.1, -0.1, -0.1)\n",
    "#std = (0.6, 0.6, 0.6)\n",
    "\n",
    "random.seed(100)\n",
    "torch.manual_seed(100)\n",
    "val_transform = transforms.Compose(\n",
    "            [   \n",
    "                transforms.RandomCrop(size=(64,64)),\n",
    "                #transforms.Resize(256),\n",
    "                #transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std),\n",
    "            ]\n",
    "        )\n",
    "x_after = val_transform(x_before)\n",
    "plt.imshow(x_after.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwith torch.no_grad():\\n    for x, y in tqdm(dataloaders['val']):\\n        y_pred = model(x)\\n        correct += (y_pred.argmax(axis=1) == y).sum().item()\\n        total += len(y)\\n        \\nprint(correct / total)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "tar_dic={'WellA1':0,'WellA2':1,'WellA3':2,'WellB1':3}\n",
    "class AMDEMTBatch9(Dataset):\n",
    "    def __init__(self, root, split, transform=None):\n",
    "        self.samples = []\n",
    "        self.targets = []\n",
    "        self.transform = transform\n",
    "        samples_dir = os.path.join(root, split,'raw') # the file dir is constructed as your_dir / train(test) / raw / ..ome.tiff\n",
    "        for entry in os.listdir(samples_dir):\n",
    "            if entry.endswith('.tiff'):\n",
    "                if split == \"val\":\n",
    "                    sample_path = os.path.join(samples_dir, entry)\n",
    "                    self.samples.append(sample_path)\n",
    "                    self.targets.append(tar_dic[entry.split('_')[0]])\n",
    "                elif split == \"train\":\n",
    "                    sample_path = os.path.join(samples_dir, entry)\n",
    "                    self.samples.append(sample_path)\n",
    "                    self.targets.append(tar_dic[entry.split('_')[0]])\n",
    "    def __len__(self):\n",
    "            return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "            x = io.imread(self.samples[idx])\n",
    "            x = Image.fromarray((x / 256).astype('uint8')).convert('RGB')\n",
    "            if self.transform:\n",
    "                x = self.transform(x)\n",
    "            return x, self.targets[idx]\n",
    "    \n",
    "\n",
    "mean = (0.03, 0.08, 0.02)\n",
    "std = (0.02, 0.04, 0.04)\n",
    "\n",
    "model=dinov2_vits14_lc_batch9\n",
    "\n",
    "data_transforms = {\n",
    "'train': transforms.Compose(\n",
    "            [   \n",
    "                transforms.RandomCrop(size=(250,250)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std),\n",
    "            ]\n",
    "        ),\n",
    "'val': transforms.Compose(\n",
    "            [   \n",
    "                transforms.RandomCrop(size=(250,250)),\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std),\n",
    "            ]\n",
    "        )}\n",
    "image_datasets = {x: AMDEMTBatch9('/Users/xiatian2/VIT/batch9', x, data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "sampler = {x: RandomSampler(image_datasets[x], replacement=True, num_samples=200)\n",
    "              for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(dataset=image_datasets[x], sampler=sampler[x],batch_size=4,drop_last=True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "'''\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(dataloaders['val']):\n",
    "        y_pred = model(x)\n",
    "        correct += (y_pred.argmax(axis=1) == y).sum().item()\n",
    "        total += len(y)\n",
    "        \n",
    "print(correct / total)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.4177 Acc: 0.2250\n",
      "val Loss: 1.3985 Acc: 0.2400\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.4038 Acc: 0.2200\n",
      "val Loss: 1.3834 Acc: 0.2850\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.4047 Acc: 0.2100\n",
      "val Loss: 1.3846 Acc: 0.2700\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.3900 Acc: 0.2200\n",
      "val Loss: 1.3945 Acc: 0.2300\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.3893 Acc: 0.2350\n",
      "val Loss: 1.3904 Acc: 0.2500\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.3918 Acc: 0.2350\n",
      "val Loss: 1.3937 Acc: 0.2350\n",
      "Epoch 6/19\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m running_loss,running_corrects,total\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m dataloaders[phase]:\n\u001b[0;32m---> 26\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     28\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/swin_unetr/lib/python3.12/site-packages/torch/_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/swin_unetr/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:451\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/anaconda3/envs/swin_unetr/lib/python3.12/site-packages/torch/optim/optimizer.py:825\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m set_to_none:\n\u001b[0;32m--> 825\u001b[0m         p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mgrad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#optimize whole network\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "#scheduler= optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "#for param in model.parameters():\n",
    "#    param.requires_grad = False\n",
    "#num_ftrs = model.linear_head.in_features\n",
    "#model.linear_head = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "best_acc=0.0\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch}/{epochs - 1}')\n",
    "    print('-' * 10)\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "        \n",
    "        running_loss,running_corrects,total=0,0,0\n",
    "        for x, y in dataloaders[phase]:\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                output = model(x)\n",
    "                _, preds = torch.max(output, 1)\n",
    "                loss = criterion(output, y)\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * x.size(0)\n",
    "            running_corrects += torch.sum(preds == y.data)\n",
    "            total += len(y)\n",
    "        #if phase == 'train':    \n",
    "           # scheduler.step()\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = running_corrects.double() / total\n",
    "\n",
    "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "        if phase == 'val' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            torch.save(model.state_dict(), '10epoch_fewshot_dinov2_vits14_lc_batch9.pth')\n",
    "\n",
    "print(f'Best val Acc: {best_acc:4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swin_unetr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
